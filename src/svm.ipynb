{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f320300",
   "metadata": {},
   "source": [
    "```markdown\n",
    "# üìù Text Classification with TF-IDF + SVM and MLflow\n",
    "\n",
    "This notebook trains a **TF-IDF + SVM** classifier for text classification and logs results with **MLflow**.\n",
    "\n",
    "Pipeline:\n",
    "1. Load and preprocess dataset\n",
    "2. TF-IDF vectorization\n",
    "3. Train **SVM** with hyperparameter tuning\n",
    "4. Calibrate classifier to output probabilities\n",
    "5. Evaluate with CV, accuracy, and F1 score\n",
    "6. Log results and model to **MLflow**\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5196e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f929004a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/medhedimaaroufi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/medhedimaaroufi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/medhedimaaroufi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üì• Download NLTK resources\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58d1410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Set MLflow Tracking URI\n",
    "mlflow.set_tracking_uri(\"http://localhost:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d40b2cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. 47837 samples.\n"
     ]
    }
   ],
   "source": [
    "# üìÇ Load and preprocess dataset\n",
    "def load_data(dataset_path=\"../dataset/all_tickets_processed_improved_v3.csv\"):\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    if 'Document' not in df.columns or 'Topic_group' not in df.columns:\n",
    "        raise ValueError(\"Dataset must contain 'Document' and 'Topic_group' columns\")\n",
    "    \n",
    "    # Stopwords + Lemmatizer\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english')) | {'please', 'ticket', 'help'}\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def preprocess_text(text):\n",
    "        text = re.sub(r'[^\\w\\s]', '', text.lower())  \n",
    "        tokens = re.findall(r'\\w+', text)\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    df['Document'] = df['Document'].apply(preprocess_text)\n",
    "    return df['Document'].values, df['Topic_group'].values\n",
    "\n",
    "X, y = load_data()\n",
    "print(f\"Dataset loaded. {len(X)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79572102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèãÔ∏è Train TF-IDF + SVM model\n",
    "def train_tfidf_svm(X, y):\n",
    "    # Vectorizer\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1, 3), \n",
    "        max_features=10000, \n",
    "        min_df=5, \n",
    "        sublinear_tf=True\n",
    "    )\n",
    "    X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "    # Grid Search for best C\n",
    "    param_grid = {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l2']}\n",
    "    svm = LinearSVC(class_weight='balanced', max_iter=2000)\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=3, scoring='f1_weighted')\n",
    "    grid_search.fit(X_tfidf, y)\n",
    "\n",
    "    # Calibrate for probabilities\n",
    "    best_svm = grid_search.best_estimator_\n",
    "    calibrated_svm = CalibratedClassifierCV(best_svm, cv=3)\n",
    "    calibrated_svm.fit(X_tfidf, y)\n",
    "\n",
    "    # Cross-validation accuracy\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(best_svm, X_tfidf, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = calibrated_svm.predict(X_tfidf)\n",
    "    probabilities = calibrated_svm.predict_proba(X_tfidf)\n",
    "\n",
    "    return calibrated_svm, vectorizer, y, y_pred, probabilities, cv_scores.mean()\n",
    "\n",
    "model, vectorizer, y_true, y_pred, probs, cv_accuracy = train_tfidf_svm(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0636bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Accuracy: 0.8866\n",
      "‚úÖ F1 Score: 0.8867\n",
      "‚úÖ CV Accuracy: 0.8525\n"
     ]
    }
   ],
   "source": [
    "# üìä Evaluate model\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f\"‚úÖ Accuracy: {accuracy:.4f}\")\n",
    "print(f\"‚úÖ F1 Score: {f1:.4f}\")\n",
    "print(f\"‚úÖ CV Accuracy: {cv_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9549c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/01 22:12:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/01 22:12:13 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    \"new hardware issue\"\n",
      "  ]\n",
      "}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: Invalid input. could not convert string to float: 'new hardware issue'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run amazing-horse-967 at: http://localhost:8080/#/experiments/0/runs/3fd3653a2e7143afa88f340538b1db5a\n",
      "üß™ View experiment at: http://localhost:8080/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# üìà Log with MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model\", \"TF-IDF + SVM\")\n",
    "    mlflow.log_param(\"ngram_range\", \"(1, 3)\")\n",
    "    mlflow.log_param(\"max_features\", 10000)\n",
    "    mlflow.log_param(\"min_df\", 5)\n",
    "    mlflow.log_param(\"sublinear_tf\", True)\n",
    "    mlflow.log_param(\"best_C\", model.calibrated_classifiers_[0].estimator.C)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"cv_accuracy\", cv_accuracy)\n",
    "\n",
    "    # Example input\n",
    "    input_example = np.array([\"new hardware issue\"])\n",
    "    X_example_tfidf = vectorizer.transform(input_example)\n",
    "    signature = infer_signature(X_example_tfidf, model.predict(X_example_tfidf))\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"tfidf_svm_model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf40edd7",
   "metadata": {},
   "source": [
    "\n",
    "# ‚úÖ Results\n",
    "\n",
    "- Accuracy, F1, and CV accuracy are printed above.\n",
    "- All metrics, parameters, and the trained model are logged in **MLflow**.\n",
    "- Open MLflow UI to explore:\n",
    "```bash\n",
    "mlflow ui --port 8080\n",
    "````\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
